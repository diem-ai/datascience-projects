{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> <p> The project aims to explore text message data, create classification models using CountVectorizer and Tf-idf Vectorizer and predict messages spam or not spam . </p>\n",
    "\n",
    "Questions come up: </h5>\n",
    "\n",
    "<p> 1) What percentage of the documents in spam_data are spam? </p>\n",
    "<p> 2) What is the longest token in the vocabulary in training set? </p>\n",
    "<p> 3) What is the average length of documents (number of characters) for not spam and spam documents? </p>\n",
    "<p> 4) What is the average number of digits per document for not spam and spam documents? </p>\n",
    "<p> 5) What is the average number of non-word characters (anything other than a letter, digit or underscore) per document for not spam and spam documents? </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Import Libraries </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Accesory functions </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_digits_text(data):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        - Count the number of digits in each doc in data\n",
    "        - Compute the average \n",
    "    \n",
    "    Arg:\n",
    "        data: array of text\n",
    "        \n",
    "    Return: \n",
    "        an average of number of digits in data\n",
    "    \"\"\"\n",
    "    avg = []\n",
    "    num_re = re.compile('[0-9]')\n",
    "    for text in data:\n",
    "        match = num_re.findall(text)\n",
    "        if(len(match) > 0):\n",
    "            avg.append(len(match))\n",
    "            \n",
    "    return np.mean(avg)\n",
    "\n",
    "\n",
    "def add_feature(X, feature_to_add):\n",
    "    \"\"\"\n",
    "    Combine new features into the training data\n",
    "    \n",
    "    Return:\n",
    "        sparse feature matrix with added feature.\n",
    "\n",
    "    Arg:\n",
    "     - X: sparse feature matrix, for example:\n",
    "         array([[   0.,    0.,    0., ...,    0.,    0.,   31.],\n",
    "           [   0.,    0.,    0., ...,    0.,    0.,  130.],\n",
    "           [   0.,    0.,    0., ...,    0.,    0.,   66.],\n",
    "           ..., \n",
    "           [   0.,    0.,    0., ...,    0.,    0.,  147.],\n",
    "           [   0.,    0.,    0., ...,    0.,    0.,   62.],\n",
    "           [   0.,    0.,    0., ...,    0.,    0.,   82.]])\n",
    "       \n",
    "     - feature_to_add: list of features, for example:\n",
    "         [[ 31, 130,  66, ..., 147,  62,  82]]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Load spam.csv, print 5 first lines </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text\n",
      "0      0  Go until jurong point, crazy.. Available only ...\n",
      "1      0                      Ok lar... Joking wif u oni...\n",
      "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      0  U dun say so early hor... U c already then say...\n",
      "4      0  Nah I don't think he goes to usf, he lives aro...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "label    5572 non-null int32\n",
      "text     5572 non-null object\n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 65.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "spam_data = pd.read_csv('data/spam.csv', sep='\\t', \n",
    "                        header=None, names=[\"label\", \"text\"])   \n",
    "\n",
    "\n",
    "spam_data['label'] = np.where(spam_data['label']=='spam', 1, 0)\n",
    "                  \n",
    "X = spam_data['text']\n",
    "y = spam_data['label']\n",
    "\n",
    "result = {}# score\n",
    "\n",
    "print(spam_data.head())\n",
    "\n",
    "print(spam_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> What percentage of the documents in spam_data are spam? </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.406317300789663"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(spam_data[spam_data['label'] == 1])/len(spam_data))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Fit the training data using a Count Vectorizer with default parameters.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_vect = count_vect.fit_transform(X)\n",
    "\n",
    "X_train_vect = count_vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> What is the longest token in the vocabulary in training set? </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hypotheticalhuagauahahuagahyuhagga', 34)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_len = {word:len(word) for word in count_vect.get_feature_names()}\n",
    "\n",
    "sorted_words_len = sorted(words_len.items(), key = lambda item: item[1], reverse=True)\n",
    "\n",
    "sorted_words_len[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Fit a fit a multinomial Naive Bayes classifier model with smoothing alpha=0.1 with cross validation </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98566308 0.98566308 0.97670251 0.98387097 0.98028674 0.98204668\n",
      " 0.98204668 0.98561151 0.97661871 0.99100719]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9829517147271354"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=0.1)\n",
    "\n",
    "scores = cross_val_score(clf, X_vect, y, cv=10)\n",
    "\n",
    "print(scores)\n",
    "\n",
    "#result.update({'MNB_vectorizer' : np.max(scores)})\n",
    "\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Fit and transform the training data using a Tfidf Vectorizer with default parameters </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>What 5 features have the smallest tf-idf and what 5 have the largest tf-idf? </p>\n",
    "\n",
    "<p>Put these features in a two series where each series is sorted by tf-idf value and then alphabetically by feature name.\n",
    "The index of the series should be the feature name, and the data should be the tf-idf.\n",
    "The series of 5 features with smallest tf-idfs should be sorted smallest tfidf first, the list of 5 features with largest tf-idfs should be sorted largest first.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proove        0.074337\n",
      "praises       0.074337\n",
      "attraction    0.074337\n",
      "makiing       0.074337\n",
      "sorrows       0.074337\n",
      "dtype: float64\n",
      "you    246.226975\n",
      "to     206.863921\n",
      "the    147.707246\n",
      "in     122.596296\n",
      "me     118.430868\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_X_tfidf = pd.DataFrame(data = X_tfidf.toarray(), columns = tfidf.get_feature_names())\n",
    "\n",
    "sums = df_X_tfidf.sum(axis=0)\n",
    "\n",
    "sorted_sums = sums.sort_values(axis=0, ascending=False)\n",
    "\n",
    "print(sorted_sums.tail(5))\n",
    "\n",
    "print(sorted_sums.head(5) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Fit and transform the training data using a Tfidf Vectorizer ignoring terms that have a document frequency strictly lower than 3.</p>\n",
    "\n",
    "<p> Then fit a multinomial Naive Bayes classifier model with smoothing alpha=0.1 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99462366 0.98387097 0.98566308 0.9874552  0.98387097 0.98204668\n",
      " 0.98743268 0.98561151 0.97661871 0.98741007]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9854603512417957"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=3)\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "clf = MultinomialNB(alpha=0.1)\n",
    "\n",
    "scores = cross_val_score(clf, X_tfidf, y, cv=10)\n",
    "\n",
    "print(scores)\n",
    "\n",
    "#result.update({'MNB_Tfidf' : np.max(scores)})\n",
    "\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> It seems that TFIDF performs a litlle bit better than Count Bag-of-word</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> What is the average length of documents (number of characters) for not spam and spam documents? </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138.6706827309237 : 71.48290155440415 )\n"
     ]
    }
   ],
   "source": [
    "avg_spam_len = [ len(text) for text in spam_data[spam_data['label'] == 1]['text']]\n",
    "avg_spam_len = np.mean(avg_spam_len)\n",
    "\n",
    "avg_ham_len = [ len(text) for text in spam_data[spam_data['label'] == 0]['text']]\n",
    "avg_ham_len = np.mean(avg_ham_len)\n",
    "\n",
    "print(\"({} : {} )\".format(avg_spam_len, avg_ham_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Add new feature: length of document and fit new training data to TFIDF </p>\n",
    "<p> Fit and transform the training datausing a Tfidf Vectorizer ignoring terms that have a document frequency strictly lower than 5. \n",
    "<p> Fit a Support Vector Classification model with regularization C=10000 and compute cross validation score for transformed test data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99462366 0.98028674 0.98207885 0.98924731 0.98207885 0.98025135\n",
      " 0.98743268 0.98561151 0.98381295 0.99100719]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9856431088406625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data['len_doc'] = spam_data['text'].apply(lambda text : len(text))\n",
    "\n",
    "#1D array\n",
    "len_docs = spam_data['len_doc'].values\n",
    "\n",
    "len_docs = len_docs.reshape(1, -1)\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=5)\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "X_tfidf = add_feature(X_tfidf, len_docs)\n",
    "\n",
    "clf = SVC(C=10000)\n",
    "\n",
    "scores = cross_val_score(clf, X_tfidf, y, cv=10)\n",
    "\n",
    "#result.update({'SVC_Tfidf' : np.max(scores)})\n",
    "\n",
    "print(scores)\n",
    "\n",
    "np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> What is the average number of digits per document for not spam and spam documents? </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16.683615819209038 : 1.9509933774834438)\n"
     ]
    }
   ],
   "source": [
    "spam_texts = spam_data.loc[spam_data['label']==1, 'text']\n",
    "\n",
    "ham_texts = spam_data.loc[spam_data['label']==0, 'text']\n",
    "\n",
    "avg_digits_spam = avg_digits_text(spam_texts)\n",
    "\n",
    "avg_digits_ham = avg_digits_text(ham_texts)\n",
    "\n",
    "print(\"({} : {})\".format(avg_digits_spam, avg_digits_ham))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Add new feature: number of digits in the document</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_re = re.compile('[0-9]')\n",
    "spam_data['num_digits'] = [len(num_re.findall(text)) for text in  spam_data['text'] ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Fit and transform the training data using a Tfidf Vectorizer ignoring terms that have a document frequency strictly lower than 5 and using word n-grams from n=1 to n=3 (unigrams, bigrams, and trigrams) </p>\n",
    "<p> Using this document-term matrix and the following additional features: <b>The length of document (number of characters) </b> and <b> number of digits per document </b> </p>\n",
    "<p> Fit a Logistic Regression model with <b> regularization C=1000000 </b> and compute cross validation score using the transformed test data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99283154 0.98566308 0.99283154 0.99283154 0.98924731 0.98563734\n",
      " 0.994614   0.98741007 0.98741007 0.99280576]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9901282263700825"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=5, ngram_range=(1,3))\n",
    "\n",
    "# Transformed train set\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "# New features added to train set\n",
    "len_docs = spam_data['len_doc']\n",
    "num_digits = spam_data['num_digits']\n",
    "\n",
    "X_tfidf = add_feature(X_tfidf, len_docs.values.reshape(1, -1))\n",
    "X_tfidf = add_feature(X_tfidf, num_digits.values.reshape(1, -1))\n",
    "\n",
    "# Fit classifier with train set\n",
    "clf = LogisticRegression(C=1000000)\n",
    "\n",
    "scores = cross_val_score(clf, X_tfidf, y, cv=10)\n",
    "\n",
    "#result.update({'Logistic_Tfidf' : np.max(scores)})\n",
    "\n",
    "print(scores)\n",
    "\n",
    "np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>What is the average number of non-word characters (anything other than a letter, digit or underscore) per document for not spam and spam documents?</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average of number of bad characters in spam message: 29.104417670682732\n",
      "average of number of bad characters in ham message: 17.396683937823834\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>len_doc</th>\n",
       "      <th>num_digits</th>\n",
       "      <th>bad_carac_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  len_doc  \\\n",
       "0      0  Go until jurong point, crazy.. Available only ...      111   \n",
       "1      0                      Ok lar... Joking wif u oni...       29   \n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...      155   \n",
       "3      0  U dun say so early hor... U c already then say...       49   \n",
       "4      0  Nah I don't think he goes to usf, he lives aro...       61   \n",
       "\n",
       "   num_digits  bad_carac_count  \n",
       "0           0               28  \n",
       "1           0               11  \n",
       "2          25               33  \n",
       "3           0               16  \n",
       "4           0               14  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_bad_carac = re.compile('\\W')\n",
    "\n",
    "spam_data['bad_carac_count'] = [len(re_bad_carac.findall(text)) for text in spam_data['text']]\n",
    "\n",
    "print(\"average of number of bad characters in spam message: {}\".format(np.mean(spam_data[spam_data['label'] == 1]['bad_carac_count'].values)))\n",
    "\n",
    "print(\"average of number of bad characters in ham message: {}\".format(np.mean(spam_data[spam_data['label'] == 0]['bad_carac_count'].values)))\n",
    "\n",
    "spam_data[spam_data['bad_carac_count'] > 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Add a new feature to spam_data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data['bad_carac_count'] = [len(re_bad_carac.findall(text)) for text in spam_data['text']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Fit and transform the training data X_train using a Count Vectorizer ignoring terms that have a document frequency strictly lower than 5 and using character n-grams from n=2 to n=5.</p>\n",
    "<p>Fit and transform data using CountVectorizer ignoring terms that have a document frequency strictly lower than 5 and using character n-grams from n=2 to n=5, using use character n-grams pass in analyzer='char_wb' which creates character n-grams only from text inside word boundaries.</p>\n",
    "<p>Using this document-term matrix and the following additional features: <b>the length of document (number of characters), number of digits per document, number of non-word characters </b></p>\n",
    "<p>Fit a Logistic Regression model with regularization C=10000 and compute cross validation score.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99103943 0.98566308 0.99641577 0.99641577 0.99103943 0.98563734\n",
      " 0.99281867 0.98741007 0.98741007 0.99460432]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9908453951496821"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=5, ngram_range=(2,5), analyzer='char_wb')\n",
    "\n",
    "# Transformed train set\n",
    "X_vect = vectorizer.fit_transform(X)\n",
    "\n",
    "# New features added to train set\n",
    "len_docs = spam_data['len_doc']\n",
    "num_digits = spam_data['num_digits']\n",
    "bad_carac_count = spam_data['bad_carac_count']\n",
    "\n",
    "X_vect = add_feature(X_vect, len_docs.values.reshape(1, -1))\n",
    "X_vect = add_feature(X_vect, num_digits.values.reshape(1, -1))\n",
    "X_vect = add_feature(X_vect, bad_carac_count.values.reshape(1, -1))\n",
    "\n",
    "# Fit classifier with train set\n",
    "clf = LogisticRegression(C=10000)\n",
    "\n",
    "scores = cross_val_score(clf, X_vect, y, cv=10)\n",
    "\n",
    "print(scores)\n",
    "\n",
    "np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
